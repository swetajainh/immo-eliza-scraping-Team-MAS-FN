{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing city: gent/9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to output_data/gent_9000_property_data.csv\n",
      "Finished processing city: gent/9000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def http_get(url):\n",
    "    # Add your implementation for http_get if needed\n",
    "    pass\n",
    "\n",
    "def extract_property_data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad responses\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Example: Extract data from the webpage\n",
    "        property_info = soup.select_one('p.classified__information--property')\n",
    "        data = {\n",
    "            'URL': url,\n",
    "            'Some_Property_Info': property_info.text.strip() if property_info else 'N/A',\n",
    "            # ... (add more fields as needed)\n",
    "        }\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for URL {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    cities_oost = [\"gent/9000\"]\n",
    "    for c in cities_oost:\n",
    "        try:\n",
    "            immoweb_urls = make_urls_immoweb([c])\n",
    "            print(f\"Processing city: {c}\")\n",
    "            data = main_immoweb(immoweb_urls)\n",
    "            save_to_csv(c, data)\n",
    "            print(f\"Finished processing city: {c}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for city {c}: {e}\")\n",
    "\n",
    "def make_urls_immoweb(cities_oost):\n",
    "    url = []\n",
    "    for c in cities_oost:\n",
    "        url.append(f\"https://www.immoweb.be/en/search/bungalow/for-sale/{c}\")\n",
    "        url.append(f\"https://www.immoweb.be/en/search/castle/for-sale/{c}\")\n",
    "    return url\n",
    "\n",
    "def main_immoweb(urls):\n",
    "    data_list = []\n",
    "    for url in urls:\n",
    "        data = extract_property_data(url)\n",
    "        if data:\n",
    "            data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "def save_to_csv(city, data_list):\n",
    "    csv_filename = f\"{city.replace('/', '_')}_property_data.csv\"\n",
    "    directory = \"output_data\"  # Adjust this directory as needed\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    csv_path = os.path.join(directory, csv_filename)\n",
    "\n",
    "    with open(csv_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = ['URL', 'Some_Property_Info']  # Add more field names as needed\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for data in data_list:\n",
    "            writer.writerow(data)\n",
    "\n",
    "    print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Message: \n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:187:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:505:5\n",
      "element.find/</<@chrome://remote/content/marionette/element.sys.mjs:135:16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Set up the WebDriver (adjust the path to your WebDriver executable)\n",
    "driver = webdriver.Firefox()\n",
    "\n",
    "# Example URL\n",
    "url = \"https://www.immoweb.be/en/search/bungalow/for-sale/gent/9000\"\n",
    "\n",
    "try:\n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the element to be present (adjust timeout as needed)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '#lazy-loading-observer-wrapper-945db8141d6082deddfef99e308747e40de02b37-classified_11006334 > h2:nth-child(1)')))\n",
    "\n",
    "    # Find the element using the CSS selector\n",
    "    your_element = driver.find_element(By.CSS_SELECTOR, '#lazy-loading-observer-wrapper-945db8141d6082deddfef99e308747e40de02b37-classified_11006334 > h2:nth-child(1)')\n",
    "\n",
    "    # Do something with the element, for example, print its text\n",
    "    print(\"Element Text:\", your_element.text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    # Close the WebDriver session\n",
    "    driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"window-size=1400,600\")\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()\n",
    "a = ua.random\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "driver = webdriver.Chrome('/Users/raduulea/Documents/chromedriver', options=options)\n",
    "\n",
    "# Replace the URL with the Immoweb search URL you are interested in\n",
    "driver.get('https://www.immoweb.be/en/search/house/for-sale')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "Title = []\n",
    "address = []\n",
    "price = []\n",
    "surface = []\n",
    "desc = []\n",
    "\n",
    "while True:\n",
    "    time.sleep(10)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.find_all(\"div\", {\"class\": \"result-xl\"})\n",
    "    for result in results:\n",
    "        Title.append(result.find(\"div\", {\"class\": \"title-bar-left\"}).get_text().strip())\n",
    "        address.append(result.find(\"span\", {\"result-adress\"}).get_text().strip())\n",
    "        price.append(result.find(\"div\", {\"class\": \"xl-price rangePrice\"}).get_text().strip())\n",
    "        surface.append(result.find(\"div\", {\"class\": \"xl-surface-ch\"}).get_text().strip())\n",
    "        desc.append(result.find(\"div\", {\"class\": \"xl-desc\"}).get_text().strip())\n",
    "\n",
    "    # Add logic to navigate to the next page using Immoweb's pagination\n",
    "    next_button = driver.find_element_by_css_selector(\"a.next\")\n",
    "    if next_button and next_button.is_enabled():\n",
    "        next_button.click()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame({\"Title\": Title, \"Address\": address, \"Price:\": price, \"Surface\": surface, \"Description\": desc})\n",
    "df.to_csv(\"output_immoweb.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"window-size=1400,600\")\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "driver = webdriver.Chrome('/Users/raduulea/Documents/chromedriver', chrome_options=options)\n",
    "\n",
    "driver.get('https://www.immoweb.be/fr/recherche/immeuble-de-rapport/a-vendre')\n",
    "\n",
    "# Rest of your script...\n",
    "time.sleep(10)\n",
    "\n",
    "Title = []\n",
    "address = []\n",
    "price = []\n",
    "surface = []\n",
    "desc = []\n",
    "\n",
    "while True:\n",
    "    time.sleep(10)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.find_all(\"div\", {\"class\": \"result-xl\"})\n",
    "    for result in results:\n",
    "        Title.append(result.find(\"div\", {\"class\": \"title-bar-left\"}).get_text().strip())\n",
    "        address.append(result.find(\"span\", {\"result-adress\"}).get_text().strip())\n",
    "        price.append(result.find(\"div\", {\"class\": \"xl-price rangePrice\"}).get_text().strip())\n",
    "        surface.append(result.find(\"div\", {\"class\": \"xl-surface-ch\"}).get_text().strip())\n",
    "        desc.append(result.find(\"div\", {\"class\": \"xl-desc\"}).get_text().strip())\n",
    "\n",
    "    # Add logic to navigate to the next page using Immoweb's pagination\n",
    "    next_button = driver.find_element_by_css_selector(\"a.next\")\n",
    "    if next_button and next_button.is_enabled():\n",
    "        next_button.click()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame({\"Title\": Title, \"Address\": address, \"Price:\": price, \"Surface\": surface, \"Description\": desc})\n",
    "df.to_csv(\"output_immoweb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"window-size=1400,600\")\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "driver = webdriver.Chrome('/Users/raduulea/Documents/chromedriver', options=options)\n",
    "\n",
    "driver.get('https://www.immoweb.be/fr/recherche/immeuble-de-rapport/a-vendre')\n",
    "\n",
    "# Rest of your script...\n",
    "time.sleep(10)\n",
    "\n",
    "Title = []\n",
    "address = []\n",
    "price = []\n",
    "surface = []\n",
    "desc = []\n",
    "\n",
    "while True:\n",
    "    time.sleep(10)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.find_all(\"div\", {\"class\": \"result-xl\"})\n",
    "    for result in results:\n",
    "        Title.append(result.find(\"div\", {\"class\": \"title-bar-left\"}).get_text().strip())\n",
    "        address.append(result.find(\"span\", {\"result-adress\"}).get_text().strip())\n",
    "        price.append(result.find(\"div\", {\"class\": \"xl-price rangePrice\"}).get_text().strip())\n",
    "        surface.append(result.find(\"div\", {\"class\": \"xl-surface-ch\"}).get_text().strip())\n",
    "        desc.append(result.find(\"div\", {\"class\": \"xl-desc\"}).get_text().strip())\n",
    "\n",
    "    # Add logic to navigate to the next page using Immoweb's pagination\n",
    "    next_button = driver.find_element_by_css_selector(\"a.next\")\n",
    "    if next_button and next_button.is_enabled():\n",
    "        next_button.click()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame({\"Title\": Title, \"Address\": address, \"Price:\": price, \"Surface\": surface, \"Description\": desc})\n",
    "df.to_csv(\"output_immoweb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/117.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "\n",
    "options = FirefoxOptions()\n",
    "options.add_argument(\"--width=1400\")\n",
    "options.add_argument(\"--height=600\")\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "# Use webdriver.Firefox instead of webdriver.Chrome\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "driver.get('https://www.immoweb.be/fr/recherche/immeuble-de-rapport/a-vendre')\n",
    "\n",
    "# Rest of your script...\n",
    "time.sleep(10)\n",
    "\n",
    "Title = []\n",
    "address = []\n",
    "price = []\n",
    "surface = []\n",
    "desc = []\n",
    "\n",
    "while True:\n",
    "    time.sleep(10)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.find_all(\"div\", {\"class\": \"result-xl\"})\n",
    "    for result in results:\n",
    "        Title.append(result.find(\"div\", {\"class\": \"title-bar-left\"}).get_text().strip())\n",
    "        address.append(result.find(\"span\", {\"result-adress\"}).get_text().strip())\n",
    "        price.append(result.find(\"div\", {\"class\": \"xl-price rangePrice\"}).get_text().strip())\n",
    "        surface.append(result.find(\"div\", {\"class\": \"xl-surface-ch\"}).get_text().strip())\n",
    "        desc.append(result.find(\"div\", {\"class\": \"xl-desc\"}).get_text().strip())\n",
    "\n",
    "# Add logic to navigate to the next page using Immoweb's pagination\n",
    "next_button = driver.find_element(By.CSS_SELECTOR, \"a.next\")\n",
    "if next_button and next_button.is_enabled():\n",
    "    next_button.click()\n",
    "else:\n",
    "    break\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"Title\": Title, \"Address\": address, \"Price:\": price, \"Surface\": surface, \"Description\": desc})\n",
    "df.to_csv(\"output_immoweb.csv\")\n",
    "\n",
    "# Close the WebDriver session\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# ...\n",
    "\n",
    "# Wait for the next button to be present on the page\n",
    "next_button = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, \"a.next\"))\n",
    ")\n",
    "\n",
    "# Check if the next button is enabled before clicking\n",
    "if next_button.is_enabled():\n",
    "    next_button.click()\n",
    "\n",
    "\n",
    "options = FirefoxOptions()\n",
    "options.add_argument(\"--width=1400\")\n",
    "options.add_argument(\"--height=600\")\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "# Use webdriver.Firefox instead of webdriver.Chrome\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "driver.get('https://www.immoweb.be/en/search/house/for-sale')\n",
    "\n",
    "# Rest of your script...\n",
    "time.sleep(10)\n",
    "\n",
    "Title = []\n",
    "address = []\n",
    "price = []\n",
    "surface = []\n",
    "desc = []\n",
    "page = 3\n",
    "\n",
    "while True:\n",
    "    time.sleep(10)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.find_all(\"div\", {\"class\": \"result-xl\"})\n",
    "    for result in results:\n",
    "        Title.append(result.find(\"div\", {\"class\": \"title-bar-left\"}).get_text().strip())\n",
    "        address.append(result.find(\"span\", {\"result-adress\"}).get_text().strip())\n",
    "        price.append(result.find(\"div\", {\"class\": \"xl-price rangePrice\"}).get_text().strip())\n",
    "        surface.append(result.find(\"div\", {\"class\": \"xl-surface-ch\"}).get_text().strip())\n",
    "        desc.append(result.find(\"div\", {\"class\": \"xl-desc\"}).get_text().strip())\n",
    "\n",
    "    # Add logic to navigate to the next page using Immoweb's pagination\n",
    "    next_button = driver.find_element(By.CSS_SELECTOR, \"a.next\")\n",
    "    if next_button and next_button.is_enabled():\n",
    "        next_button.click()\n",
    "        page += 1\n",
    "        # It will traverse for only 3 pages as you are after, if you want more pages, just comment the below if block\n",
    "        if int(page) > 3:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame({\"Title\": Title, \"Address\": address, \"Price:\": price, \"Surface\": surface, \"Description\": desc})\n",
    "df.to_csv(\"output_immoweb.csv\")\n",
    "\n",
    "# Close the WebDriver session\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# ...\n",
    "\n",
    "# Wait for the next button to be present on the page\n",
    "next_button = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, \"a.next\"))\n",
    ")\n",
    "\n",
    "# Check if the next button is enabled before clicking\n",
    "if next_button.is_enabled():\n",
    "    next_button.click()\n",
    "\n",
    "\n",
    "options = FirefoxOptions()\n",
    "options.add_argument(\"--width=1400\")\n",
    "options.add_argument(\"--height=600\")\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "# Use webdriver.Firefox instead of webdriver.Chrome\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "driver.get('https://www.immoweb.be/en/search/house/for-sale')\n",
    "\n",
    "# Rest of your script...\n",
    "time.sleep(10)\n",
    "\n",
    "Title = []\n",
    "address = []\n",
    "price = []\n",
    "surface = []\n",
    "desc = []\n",
    "page = 3\n",
    "\n",
    "while True:\n",
    "    time.sleep(10)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.find_all(\"div\", {\"class\": \"result-xl\"})\n",
    "try: # Find the table with class \"classified-table\" table = driver.find_element(By.CLASS_NAME, 'classified-table')\n",
    "                # Find all rows in the table rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "    for row in rows: # Find the associated header for each row header = row.find_element(By.CLASS_NAME, 'classified-table__header').text.strip()\n",
    " for cell in cells: # Extract and print the text content of each cell along with its associated header print(f\"{header}: {cell.text.strip()}\")\n",
    "\n",
    "except Exception as e: print(\"Error occurred:\", e)\n",
    "\n",
    "finally: # Quit the WebDriver driver.quit()\n",
    " # Find all cells in the row cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    for result in results:\n",
    "        Title.append(result.find(\"div\", {\"class\": \"title-bar-left\"}).get_text().strip())\n",
    "        address.append(result.find(\"span\", {\"result-adress\"}).get_text().strip())\n",
    "        price.append(result.find(\"div\", {\"class\": \"xl-price rangePrice\"}).get_text().strip())\n",
    "        surface.append(result.find(\"div\", {\"class\": \"xl-surface-ch\"}).get_text().strip())\n",
    "        desc.append(result.find(\"div\", {\"class\": \"xl-desc\"}).get_text().strip())\n",
    "\n",
    "    # Add logic to navigate to the next page using Immoweb's pagination\n",
    "    next_button = driver.find_element(By.CSS_SELECTOR, \"a.next\")\n",
    "    if next_button and next_button.is_enabled():\n",
    "        next_button.click()\n",
    "        page += 1\n",
    "        # It will traverse for only 3 pages as you are after, if you want more pages, just comment the below if block\n",
    "        if int(page) > 3:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame({\"Title\": Title, \"Address\": address, \"Price:\": price, \"Surface\": surface, \"Description\": desc})\n",
    "df.to_csv(\"output_immoweb.csv\")\n",
    "\n",
    "# Close the WebDriver session\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "options = FirefoxOptions()\n",
    "options.add_argument(\"--width=1400\")\n",
    "options.add_argument(\"--height=600\")\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "# Use webdriver.Firefox instead of webdriver.Chrome\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "driver.get('https://www.immoweb.be/en/search/house/for-sale')\n",
    "\n",
    "# Rest of your script...\n",
    "time.sleep(10)\n",
    "\n",
    "Title = []\n",
    "address = []\n",
    "price = []\n",
    "surface = []\n",
    "desc = []\n",
    "page = 3\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        results = soup.find_all(\"div\", {\"class\": \"result-xl\"})\n",
    "\n",
    "        for result in results:\n",
    "            Title.append(result.find(\"div\", {\"class\": \"title-bar-left\"}).get_text().strip())\n",
    "            address.append(result.find(\"span\", {\"result-adress\"}).get_text().strip())\n",
    "            price.append(result.find(\"div\", {\"class\": \"xl-price rangePrice\"}).get_text().strip())\n",
    "            surface.append(result.find(\"div\", {\"class\": \"xl-surface-ch\"}).get_text().strip())\n",
    "            desc.append(result.find(\"div\", {\"class\": \"xl-desc\"}).get_text().strip())\n",
    "\n",
    "        # Add logic to navigate to the next page using Immoweb's pagination\n",
    "        next_button = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"a.next\"))\n",
    "        )\n",
    "\n",
    "        if next_button.is_enabled():\n",
    "            next_button.click()\n",
    "            page += 1\n",
    "            # It will traverse for only 3 pages as you are after, if you want more pages, just comment the below if block\n",
    "            if int(page) > 3:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error occurred:\", e)\n",
    "\n",
    "finally:\n",
    "    df = pd.DataFrame({\"Title\": Title, \"Address\": address, \"Price\": price, \"Surface\": surface, \"Description\": desc})\n",
    "    df.to_csv(\"output_immoweb.csv\")\n",
    "\n",
    "    # Close the WebDriver session\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Windows NT 10.0; rv:102.0) Gecko/20100101 Firefox/102.0\n",
      "Error occurred: Message: \n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:187:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:505:5\n",
      "element.find/</<@chrome://remote/content/marionette/element.sys.mjs:135:16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "options = FirefoxOptions()\n",
    "options.add_argument(\"--width=1400\")\n",
    "options.add_argument(\"--height=600\")\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "# Use webdriver.Firefox instead of webdriver.Chrome\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "try:\n",
    "    driver.get('https://www.immoweb.be/en/search/house/for-sale')\n",
    "    time.sleep(10)\n",
    "\n",
    "    Title = []\n",
    "    address = []\n",
    "    price = []\n",
    "    surface = []\n",
    "    desc = []\n",
    "    page = 3\n",
    "\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        results = soup.find_all(\"div\", {\"class\": \"result-xl\"})\n",
    "\n",
    "        for result in results:\n",
    "            Title.append(result.find(\"div\", {\"class\": \"title-bar-left\"}).get_text().strip())\n",
    "            address.append(result.find(\"span\", {\"result-adress\"}).get_text().strip())\n",
    "            price.append(result.find(\"div\", {\"class\": \"xl-price rangePrice\"}).get_text().strip())\n",
    "            surface.append(result.find(\"div\", {\"class\": \"xl-surface-ch\"}).get_text().strip())\n",
    "            desc.append(result.find(\"div\", {\"class\": \"xl-desc\"}).get_text().strip())\n",
    "\n",
    "        # Add logic to navigate to the next page using Immoweb's pagination\n",
    "        next_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.next\"))\n",
    "        )\n",
    "\n",
    "        next_button.click()\n",
    "        page += 1\n",
    "        # It will traverse for only 3 pages as you are after, if you want more pages, just comment the below if block\n",
    "        if int(page) > 3:\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error occurred:\", e)\n",
    "\n",
    "finally:\n",
    "    df = pd.DataFrame({\"Title\": Title, \"Address\": address, \"Price\": price, \"Surface\": surface, \"Description\": desc})\n",
    "    df.to_csv(\"output_immoweb.csv\")\n",
    "\n",
    "    # Close the WebDriver session\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "options = FirefoxOptions()\n",
    "options.add_argument(\"--width=1400\")\n",
    "options.add_argument(\"--height=600\")\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "# Use webdriver.Firefox instead of webdriver.Chrome\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "try:\n",
    "    driver.get('https://www.immoweb.be/en/search/house/for-sale')\n",
    "    time.sleep(10)\n",
    "\n",
    "    Title = []\n",
    "    address = []\n",
    "    price = []\n",
    "    surface = []\n",
    "    desc = []\n",
    "    page = 3\n",
    "\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        results = soup.find_all(\"div\", {\"class\": \"result-xl\"})\n",
    "\n",
    "        for result in results:\n",
    "            Title.append(result.find(\"div\", {\"class\": \"title-bar-left\"}).get_text().strip())\n",
    "            address.append(result.find(\"span\", {\"result-adress\"}).get_text().strip())\n",
    "            price.append(result.find(\"div\", {\"class\": \"xl-price rangePrice\"}).get_text().strip())\n",
    "            surface.append(result.find(\"div\", {\"class\": \"xl-surface-ch\"}).get_text().strip())\n",
    "            desc.append(result.find(\"div\", {\"class\": \"xl-desc\"}).get_text().strip())\n",
    "\n",
    "        # Add logic to navigate to the next page using Immoweb's pagination\n",
    "        next_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.next\"))\n",
    "        )\n",
    "\n",
    "        next_button.click()\n",
    "        page += 1\n",
    "        # It will traverse for only 3 pages as you are after, if you want more pages, just comment the below if block\n",
    "        if int(page) > 3:\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error occurred:\", e)\n",
    "\n",
    "finally:\n",
    "    df = pd.DataFrame({\"Title\": Title, \"Address\": address, \"Price\": price, \"Surface\": surface, \"Description\": desc})\n",
    "    df.to_csv(\"output_immoweb.csv\")\n",
    "\n",
    "    # Close the WebDriver session\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: Message: Unable to locate element: .classified-table; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:187:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:505:5\n",
      "element.find/</<@chrome://remote/content/marionette/element.sys.mjs:135:16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Set up Selenium WebDriver (make sure to install the appropriate driver for your browser)\n",
    "driver = webdriver.Firefox()  # Change this to the appropriate driver for your browser\n",
    "\n",
    "# Define the base URL\n",
    "base_url = \"https://www.immoweb.be/en/search/house/for-sale\"\n",
    "\n",
    "# Define the number of pages to scrape\n",
    "num_pages = 3\n",
    "\n",
    "# Lists to store data\n",
    "titles = []\n",
    "addresses = []\n",
    "prices = []\n",
    "surfaces = []\n",
    "descriptions = []\n",
    "\n",
    "try:\n",
    "    for page in range(1, num_pages + 1):\n",
    "        # Construct the URL for each page\n",
    "        url = f\"{base_url}?page={page}\"\n",
    "\n",
    "        # Load the page\n",
    "        driver.get(url)\n",
    "\n",
    "        # Find the table with class \"classified-table\"\n",
    "        table = driver.find_element(By.CLASS_NAME, 'classified-table')\n",
    "\n",
    "        # Find all rows in the table\n",
    "        rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "        for row in rows:\n",
    "            # Find the associated header for each row\n",
    "            header = row.find_element(By.CLASS_NAME, 'classified-table__header').text.strip()\n",
    "\n",
    "            # Find all cells in the row\n",
    "            cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "\n",
    "            for cell in cells:\n",
    "                # Extract and store the text content of each cell based on its associated header\n",
    "                if header == 'Title':\n",
    "                    titles.append(cell.text.strip())\n",
    "                elif header == 'Address':\n",
    "                    addresses.append(cell.text.strip())\n",
    "                elif header == 'Price':\n",
    "                    prices.append(cell.text.strip())\n",
    "                elif header == 'Surface':\n",
    "                    surfaces.append(cell.text.strip())\n",
    "                elif header == 'Description':\n",
    "                    descriptions.append(cell.text.strip())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error occurred:\", e)\n",
    "\n",
    "finally:\n",
    "    # Quit the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame({\"Title\": titles, \"Address\": addresses, \"Price\": prices, \"Surface\": surfaces, \"Description\": descriptions})\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(\"output_immoweb.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Set up Selenium WebDriver (make sure to install the appropriate driver for your browser)\n",
    "options = Options()\n",
    "options.headless = True  # Set to True if you don't want a visible browser window\n",
    "driver = webdriver.Chrome(options=options)  # Change this to the appropriate driver for your browser\n",
    "\n",
    "# Define the base URL\n",
    "base_url = \"https://www.immoweb.be/en/classified/house/for-sale\"\n",
    "\n",
    "# Define the number of pages to scrape\n",
    "num_pages = 3\n",
    "\n",
    "try:\n",
    "    for page in range(1, num_pages + 1):\n",
    "        # Construct the URL for each page\n",
    "        url = f\"{base_url}?page={page}\"\n",
    "\n",
    "        # Load the page\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Find all tables with class \"classified-table\"\n",
    "        tables = driver.find_elements(By.CSS_SELECTOR, 'table.classified-table')\n",
    "\n",
    "        for table in tables:\n",
    "            print(\"Table found:\")\n",
    "\n",
    "            # Find all rows in the table\n",
    "            rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "            for row in rows:\n",
    "                # Find the associated header for each row\n",
    "                header = row.find_element(By.TAG_NAME, 'th').text.strip()\n",
    "                print(\"Header:\", header)\n",
    "\n",
    "                # Find all cells in the row\n",
    "                cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "\n",
    "                for cell in cells:\n",
    "                    # Extract and print the text content of each cell\n",
    "                    print(\"Cell:\", cell.text.strip())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error occurred:\", e)\n",
    "\n",
    "finally:\n",
    "    # Quit the WebDriver\n",
    "    driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
