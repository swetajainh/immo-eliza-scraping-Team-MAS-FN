{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a Python snippet that uses BeautifulSoup to scrape data for two properties from Immoweb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: € 419.760*                                                419760€\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_property_price(url):\n",
    "    \"\"\"\n",
    "    Get the price of a property from the given URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the property page.\n",
    "\n",
    "    Returns:\n",
    "        str: The price of the property.\n",
    "    \"\"\"\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the price element by <p> tag\n",
    "    price_element = soup.find('p', class_='classified__price').text.strip().replace('\\n', '')\n",
    "\n",
    "    return price_element\n",
    "\n",
    "# Define the URL of the property page\n",
    "url = \"https://www.immoweb.be/nl/zoekertje/appartement/te-koop/gavere/9890/11140877\"\n",
    "\n",
    "# Get the price of the property\n",
    "price = get_property_price(url)\n",
    "\n",
    "# Print the price\n",
    "print(\"Price:\", price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available as of: After signing the deed\n",
      "Construction year: 1926\n",
      "Number of floors: 2\n",
      "Building condition: Just renovated\n",
      "Street frontage width: 6 m\n",
      "Number of frontages: 3\n",
      "Covered parking spaces: 2\n",
      "Outdoor parking spaces: 2\n",
      "Surroundings type: Living area (residential, urban or rural)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def scrape_immoweb_data(url):\n",
    "    \"\"\"\n",
    "    Scrape data from an Immoweb classified page.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the Immoweb classified page.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Set up Selenium WebDriver (make sure to install the appropriate driver for your browser)\n",
    "    driver = webdriver.Chrome()  # Change this to the appropriate driver for your browser\n",
    "\n",
    "    try:\n",
    "        # Load the page\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the table to be present\n",
    "        table = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'classified-table'))\n",
    "        )\n",
    "\n",
    "        # Extract every element in the table\n",
    "        rows = table.find_elements(By.TAG_NAME, 'tr')  # Find all rows in the table\n",
    "\n",
    "        for row in rows:\n",
    "            columns = row.find_elements(By.TAG_NAME, 'td')  # Find all columns (cells) in the row\n",
    "\n",
    "            # Find the associated header for each cell in the row\n",
    "            header = row.find_element(By.TAG_NAME, 'th').text.strip()\n",
    "\n",
    "            for column in columns:\n",
    "                # Extract and print the text content of the cell along with its associated header\n",
    "                print(f\"{header}: {column.text.strip()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        # Quit the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://www.immoweb.be/en/classified/house/for-sale/anderlecht/1070/11150049\"\n",
    "\n",
    "# Call the function to scrape data\n",
    "scrape_immoweb_data(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def scrape_immoweb_data(url, csv_file):\n",
    "    \"\"\"\n",
    "    Scrape data from an Immoweb classified page and save it to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the Immoweb classified page.\n",
    "        csv_file (str): The name of the CSV file to save the data to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Set up Selenium WebDriver (make sure to install the appropriate driver for your browser)\n",
    "    driver = webdriver.Chrome()  # Change this to the appropriate driver for your browser\n",
    "\n",
    "    try:\n",
    "        # Load the page\n",
    "        driver.get(url)\n",
    "\n",
    "        with open(csv_file, mode='w', newline='', encoding='utf-8') as file:  # Specify UTF-8 encoding\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # Find all tables with class \"classified-table\"\n",
    "            tables = driver.find_elements(By.CSS_SELECTOR, 'table.classified-table')\n",
    "\n",
    "            # Loop through each table\n",
    "            for table in tables:\n",
    "                # Find all rows in the table\n",
    "                rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "                for row in rows:\n",
    "                    # Find all cells in the row\n",
    "                    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "\n",
    "                    # Check if the row contains header cells (th) or data cells (td)\n",
    "                    if row.find_elements(By.TAG_NAME, 'th'):\n",
    "                        # If the row contains header cells, extract the header text\n",
    "                        header = row.find_element(By.TAG_NAME, 'th').text.strip()\n",
    "                        row_data = [header] + [cell.text.strip() for cell in cells]\n",
    "                    else:\n",
    "                        # If the row contains data cells only, create a row with empty header\n",
    "                        row_data = [\"\"] + [cell.text.strip() for cell in cells]\n",
    "\n",
    "                    # Write the row data to the CSV file\n",
    "                    writer.writerow(row_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        # Quit the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://www.immoweb.be/en/classified/house/for-sale/anderlecht/1070/11150049\"\n",
    "\n",
    "# Define the CSV file name\n",
    "csv_file = \"immoweb_data.csv\"\n",
    "\n",
    "# Call the function to scrape data and save to CSV\n",
    "scrape_immoweb_data(url, csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.immoweb.be/nl/zoekertje/appartement/te-koop/evere/1140/11050526\n",
      "https://www.immoweb.be/nl/zoekertje/appartement/te-koop/evere/1140/11012764\n",
      "https://www.immoweb.be/nl/zoekertje/penthouse/te-koop/ukkel/1180/11154663\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def scrape_urls(start_page, last_page, num_urls=3):\n",
    "    \"\"\"\n",
    "    Scrape property URLs from Immoweb for a range of pages.\n",
    "\n",
    "    Args:\n",
    "        start_page (int): The starting page number.\n",
    "        last_page (int): The ending page number.\n",
    "        num_urls (int): The number of URLs to scrape. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Set up Selenium WebDriver\n",
    "    driver = webdriver.Chrome()  # Change this to the appropriate driver for your browser\n",
    "\n",
    "    try:\n",
    "        url_count = 0  # Initialize URL count\n",
    "        for page in range(start_page, last_page + 1):\n",
    "            # Construct the URL\n",
    "            url = f'https://www.immoweb.be/nl/zoeken/huis-en-appartement/te-koop?countries=BE&page={page}&orderBy=relevance'\n",
    "\n",
    "            # Load the page\n",
    "            driver.get(url)\n",
    "\n",
    "            # Find all property URLs\n",
    "            urls = driver.find_elements(By.CSS_SELECTOR, 'a.card__title-link')\n",
    "\n",
    "            for url_element in urls:\n",
    "                property_url = url_element.get_attribute('href')\n",
    "                print(property_url)\n",
    "                url_count += 1  # Increment URL count\n",
    "                if url_count == num_urls:\n",
    "                    break  # Exit the loop if desired number of URLs is reached\n",
    "            if url_count == num_urls:\n",
    "                break  # Exit the outer loop if desired number of URLs is reached\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        # Quit the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "# Example usage: scrape URLs from page 1 to 2 with a limit of 3 URLs\n",
    "scrape_urls(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def scrape_immoweb_data(urls, csv_file):\n",
    "    \"\"\"\n",
    "    Scrape data from Immoweb classified pages and save it to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        urls (list): A list of URLs of Immoweb classified pages.\n",
    "        csv_file (str): The name of the CSV file to save the data to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Set up Selenium WebDriver (make sure to install the appropriate driver for your browser)\n",
    "    driver = webdriver.Chrome()  # Change this to the appropriate driver for your browser\n",
    "\n",
    "    try:\n",
    "        with open(csv_file, mode='w', newline='', encoding='utf-8') as file:  # Specify UTF-8 encoding\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            for url in urls:\n",
    "                # Load the page\n",
    "                driver.get(url)\n",
    "\n",
    "                # Find all tables with class \"classified-table\"\n",
    "                tables = driver.find_elements(By.CSS_SELECTOR, 'table.classified-table')\n",
    "\n",
    "                # Loop through each table\n",
    "                for table in tables:\n",
    "                    # Find all rows in the table\n",
    "                    rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "                    for row in rows:\n",
    "                        # Find all cells in the row\n",
    "                        cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "\n",
    "                        # Check if the row contains header cells (th) or data cells (td)\n",
    "                        if row.find_elements(By.TAG_NAME, 'th'):\n",
    "                            # If the row contains header cells, extract the header text\n",
    "                            header = row.find_element(By.TAG_NAME, 'th').text.strip()\n",
    "                            row_data = [header] + [cell.text.strip() for cell in cells]\n",
    "                        else:\n",
    "                            # If the row contains data cells only, create a row with empty header\n",
    "                            row_data = [\"\"] + [cell.text.strip() for cell in cells]\n",
    "\n",
    "                        # Write the row data to the CSV file\n",
    "                        writer.writerow(row_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        # Quit the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "# Define the URLs\n",
    "urls = [\n",
    "    \"https://www.immoweb.be/en/classified/house/for-sale/anderlecht/1070/11150049\",    \n",
    "    \"https://www.immoweb.be/en/classified/house/for-sale/schaerbeek/1030/11150110\"\n",
    "]\n",
    "\n",
    "# Define the CSV file name\n",
    "csv_file = \"immoweb_data.csv\"\n",
    "\n",
    "# Call the function to scrape data and save to CSV\n",
    "scrape_immoweb_data(urls, csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def scrape_immoweb_data(urls, csv_file):\n",
    "    \"\"\"\n",
    "    Scrape data from Immoweb classified pages and save it to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        urls (list): A list of URLs of Immoweb classified pages.\n",
    "        csv_file (str): The name of the CSV file to save the data to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Set up Chrome options for headless mode\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "    # Set up Selenium WebDriver with Chrome options\n",
    "    driver = webdriver.Chrome(options=chrome_options)  # Change this to the appropriate driver for your browser\n",
    "\n",
    "    try:\n",
    "        for url in urls:\n",
    "            # Load the page\n",
    "            driver.get(url)\n",
    "            \n",
    "            # Find all tables with class \"classified-table\"\n",
    "            tables = driver.find_elements(By.CSS_SELECTOR, 'table.classified-table')\n",
    "\n",
    "            # Loop through each table\n",
    "            for table in tables:\n",
    "                # Find all rows in the table\n",
    "                rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "                for row in rows:\n",
    "                    # Find all cells in the row\n",
    "                    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "\n",
    "                    # Check if the row contains header cells (th) or data cells (td)\n",
    "                    if row.find_elements(By.TAG_NAME, 'th'):\n",
    "                        # If the row contains header cells, extract the header text\n",
    "                        header = row.find_element(By.TAG_NAME, 'th').text.strip()\n",
    "                        row_data = [header] + [cell.text.strip() for cell in cells]\n",
    "                    else:\n",
    "                        # If the row contains data cells only, create a row with empty header\n",
    "                        row_data = [\"\"] + [cell.text.strip() for cell in cells]\n",
    "\n",
    "                    # Write the row data to the CSV file\n",
    "                    with open(csv_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow(row_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        # Quit the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "# Define the URLs\n",
    "urls = [\n",
    "    \"https://www.immoweb.be/en/classified/house/for-sale/anderlecht/1070/11150049\",\n",
    "    \"https://www.immoweb.be/en/classified/house/for-sale/schaerbeek/1030/11150110\"\n",
    "]\n",
    "\n",
    "# Define the CSV file name\n",
    "csv_file = \"immoweb_data.csv\"\n",
    "\n",
    "# Call the function to scrape data and save to CSV\n",
    "scrape_immoweb_data(urls, csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables found on page: https://www.immoweb.be/en/classified/house/for-sale/anderlecht/1070/11150049\n",
      "Table 1:\n",
      "Available as of After signing the deed\n",
      "Construction year 1926\n",
      "Number of floors 2\n",
      "Building condition Just renovated\n",
      "Street frontage width 6 m\n",
      "Number of frontages 3\n",
      "Covered parking spaces 2\n",
      "Outdoor parking spaces 2\n",
      "Surroundings type Living area (residential, urban or rural)\n",
      "Table 2:\n",
      "Living area 107 m²\n",
      "square meters\n",
      "Living room surface 30 m²\n",
      "square meters\n",
      "Dining room Yes\n",
      "How many fireplaces? 1\n",
      "Kitchen type USA hyper equipped\n",
      "Kitchen surface 9 m²\n",
      "square meters\n",
      "Bedrooms 3\n",
      "Bedroom 1 surface 9 m²\n",
      "square meters\n",
      "Bedroom 2 surface 16 m²\n",
      "square meters\n",
      "Bedroom 3 surface 17 m²\n",
      "square meters\n",
      "Dressing room No\n",
      "Bathrooms 1\n",
      "Toilets 2\n",
      "Laundry room Yes\n",
      "Office No\n",
      "Professional space No\n",
      "Basement surface 9 m²\n",
      "square meters\n",
      "Attic surface 17 m²\n",
      "square meters\n",
      "Isolated Yes\n",
      "Armored door No\n",
      "Table 3:\n",
      "Surface of the plot 250 m²\n",
      "square meters\n",
      "Land is facing street No\n",
      "Wooded land No\n",
      "Plot at rear Yes\n",
      "Flat land Yes\n",
      "Connection to sewer network Connected\n",
      "Gas, water & electricity Yes\n",
      "Garden surface 18 m²\n",
      "square meters\n",
      "Garden orientation West\n",
      "Terrace surface 70 m²\n",
      "square meters\n",
      "Terrace orientation East\n",
      "Table 4:\n",
      "Caretaker No\n",
      "Elevator No\n",
      "Accessible for disabled people No\n",
      "Intercom No\n",
      "Secure access / alarm No\n",
      "Armored door No\n",
      "Air conditioning Yes\n",
      "TV cable Yes\n",
      "Visio phone No\n",
      "Jacuzzi No\n",
      "Sauna No\n",
      "Swimming pool No\n",
      "Internet Yes\n",
      "Table 5:\n",
      "Primary energy consumption 174 kWh/m²\n",
      "kilowatt hour per square meters\n",
      "Energy class D\n",
      "Reference number of the EPC report 20231016-0000658649-01-2\n",
      "CO₂ emission 33 kg CO₂/m²\n",
      "Yearly theoretical total energy consumption Not specified\n",
      "E-level (overall energy performance) 174\n",
      "Heating type Gas\n",
      "Heat pump Yes\n",
      "Photovoltaic solar panels Yes\n",
      "Thermic solar panels No\n",
      "Common water heater No\n",
      "Double glazing Yes\n",
      "Table 6:\n",
      "Obligation to build No\n",
      "Proceedings for breach of planning regulations No\n",
      "Flood zone type Non flood zone\n",
      "Table 7:\n",
      "Price € 415,000\n",
      "415000 €\n",
      "Cadastral income € 771\n",
      "771 €\n",
      "Tenement building No\n",
      "Sponsored\n",
      "Finance your purchase\n",
      "Need a loan? Get your mortgage rate in a few clicks!\n",
      "Simulate my loan\n",
      "Insure your purchase\n",
      "Your home insurance, simple, quick and complete\n",
      "Calculate my price\n",
      "Tables found on page: https://www.immoweb.be/en/classified/house/for-sale/schaerbeek/1030/11150110\n",
      "Table 1:\n",
      "Available as of To be defined\n",
      "Construction year 1948\n",
      "Building condition Good\n",
      "Street frontage width 6 m\n",
      "Number of frontages 2\n",
      "Outdoor parking spaces 2\n",
      "Surroundings type Living area (residential, urban or rural)\n",
      "Table 2:\n",
      "Living area 147 m²\n",
      "square meters\n",
      "Living room surface 31 m²\n",
      "square meters\n",
      "Kitchen type Installed\n",
      "Kitchen surface 15 m²\n",
      "square meters\n",
      "Bedrooms 3\n",
      "Bedroom 1 surface 15 m²\n",
      "square meters\n",
      "Bedroom 2 surface 11 m²\n",
      "square meters\n",
      "Bedroom 3 surface 38 m²\n",
      "square meters\n",
      "Dressing room No\n",
      "Bathrooms 2\n",
      "Toilets 2\n",
      "Office No\n",
      "Professional space No\n",
      "Basement surface 12 m²\n",
      "square meters\n",
      "Armored door No\n",
      "Table 3:\n",
      "Surface of the plot 225 m²\n",
      "square meters\n",
      "Land is facing street No\n",
      "Wooded land No\n",
      "Plot at rear No\n",
      "Flat land No\n",
      "Gas, water & electricity Yes\n",
      "Garden surface 110 m²\n",
      "square meters\n",
      "Garden orientation South East\n",
      "Terrace surface 12 m²\n",
      "square meters\n",
      "Terrace orientation South East\n",
      "Table 4:\n",
      "Caretaker No\n",
      "Elevator No\n",
      "Accessible for disabled people No\n",
      "Intercom No\n",
      "Secure access / alarm No\n",
      "Armored door No\n",
      "Air conditioning No\n",
      "TV cable Yes\n",
      "Visio phone No\n",
      "Jacuzzi No\n",
      "Sauna No\n",
      "Swimming pool No\n",
      "Internet Yes\n",
      "Table 5:\n",
      "Primary energy consumption Not specified\n",
      "Energy class B\n",
      "Reference number of the EPC report Not specified\n",
      "CO₂ emission Not specified\n",
      "Yearly theoretical total energy consumption Not specified\n",
      "Heating type Gas\n",
      "Heat pump No\n",
      "Photovoltaic solar panels No\n",
      "Thermic solar panels No\n",
      "Common water heater No\n",
      "Double glazing Yes\n",
      "Table 6:\n",
      "Type of building All kind\n",
      "Flood zone type Non flood zone\n",
      "Table 7:\n",
      "Price € 349,000\n",
      "349000 €\n",
      "Cadastral income € 416\n",
      "416 €\n",
      "Tenement building No\n",
      "Sponsored\n",
      "Finance your purchase\n",
      "Need a loan? Get your mortgage rate in a few clicks!\n",
      "Simulate my loan\n",
      "Insure your purchase\n",
      "Your home insurance, simple, quick and complete\n",
      "Calculate my price\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def scrape_immoweb_data(urls, csv_file):\n",
    "    \"\"\"\n",
    "    Scrape data from Immoweb classified pages and save it to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        urls (list): A list of URLs of Immoweb classified pages.\n",
    "        csv_file (str): The name of the CSV file to save the data to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Set up Selenium WebDriver\n",
    "    driver = webdriver.Chrome()  # Change this to the appropriate driver for your browser\n",
    "\n",
    "    try:\n",
    "        for url in urls:\n",
    "            # Load the page\n",
    "            driver.get(url)\n",
    "            \n",
    "            # Find all tables with class \"classified-table\"\n",
    "            tables = driver.find_elements(By.CSS_SELECTOR, 'table.classified-table')\n",
    "\n",
    "            # Print tables found\n",
    "            print(\"Tables found on page:\", url)\n",
    "            for idx, table in enumerate(tables, 1):\n",
    "                print(f\"Table {idx}:\")\n",
    "                print(table.text)  # Print the text content of the table\n",
    "\n",
    "                # Optionally, you can print the HTML content of the table\n",
    "                # print(table.get_attribute('innerHTML'))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        # Quit the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "# Define the URLs\n",
    "urls = [\n",
    "    \"https://www.immoweb.be/en/classified/house/for-sale/anderlecht/1070/11150049\",\n",
    "    \"https://www.immoweb.be/en/classified/house/for-sale/schaerbeek/1030/11150110\"\n",
    "]\n",
    "\n",
    "# Define the CSV file name\n",
    "csv_file = \"immoweb_data.csv\"\n",
    "\n",
    "# Call the function to scrape data and save to CSV\n",
    "scrape_immoweb_data(urls, csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will write the text content of each table found on the specified URLs to a .txt file named immoweb_data.txt. Each table's content will be separated by newline characters for better readability. Adjust the file paths and URLs as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def scrape_immoweb_data(urls, txt_file):\n",
    "    \"\"\"\n",
    "    Scrape data from Immoweb classified pages and save it to a text file.\n",
    "\n",
    "    Args:\n",
    "        urls (list): A list of URLs of Immoweb classified pages.\n",
    "        txt_file (str): The name of the text file to save the data to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Set up Selenium WebDriver\n",
    "    driver = webdriver.Chrome()  # Change this to the appropriate driver for your browser\n",
    "\n",
    "    try:\n",
    "        with open(txt_file, 'w', encoding='utf-8') as file:\n",
    "            for url in urls:\n",
    "                # Load the page\n",
    "                driver.get(url)\n",
    "                \n",
    "                # Find all tables with class \"classified-table\"\n",
    "                tables = driver.find_elements(By.CSS_SELECTOR, 'table.classified-table')\n",
    "\n",
    "                # Write tables found to the text file\n",
    "                file.write(f\"Tables found on page: {url}\\n\")\n",
    "                for idx, table in enumerate(tables, 1):\n",
    "                    file.write(f\"Table {idx}:\\n\")\n",
    "                    file.write(table.text + \"\\n\\n\")  # Write the text content of the table to the file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        # Quit the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "# Define the URLs\n",
    "urls = [\n",
    "    \"https://www.immoweb.be/en/classified/house/for-sale/anderlecht/1070/11150049\",\n",
    "    \"https://www.immoweb.be/en/classified/house/for-sale/schaerbeek/1030/11150110\"\n",
    "]\n",
    "\n",
    "# Define the text file name\n",
    "txt_file = \"immoweb_data.txt\"\n",
    "\n",
    "# Call the function to scrape data and save to a text file\n",
    "scrape_immoweb_data(urls, txt_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will create multiple threads, each responsible for scraping data from one URL. It uses a lock to synchronize file writes to ensure that data is written correctly to the text file. The total execution time of the script is printed at the end. Adjust the URLs and file paths as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def scrape_immoweb_data(url, txt_file, lock):\n",
    "    \"\"\"\n",
    "    Scrape data from an Immoweb classified page and save it to a text file.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the Immoweb classified page.\n",
    "        txt_file (str): The name of the text file to save the data to.\n",
    "        lock (threading.Lock): A lock to synchronize file writes.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Set up Selenium WebDriver\n",
    "    driver = webdriver.Chrome()  # Change this to the appropriate driver for your browser\n",
    "\n",
    "    try:\n",
    "        # Load the page\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Find all tables with class \"classified-table\"\n",
    "        tables = driver.find_elements(By.CSS_SELECTOR, 'table.classified-table')\n",
    "\n",
    "        # Write tables found to the text file\n",
    "        with lock:\n",
    "            with open(txt_file, 'a', encoding='utf-8') as file:\n",
    "                file.write(f\"Tables found on page: {url}\\n\")\n",
    "                for idx, table in enumerate(tables, 1):\n",
    "                    file.write(f\"Table {idx}:\\n\")\n",
    "                    file.write(table.text + \"\\n\\n\")  # Write the text content of the table to the file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        # Quit the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "def main():\n",
    "    # Define the URLs\n",
    "    urls = [\n",
    "        \"https://www.immoweb.be/en/classified/house/for-sale/anderlecht/1070/11150049\",\n",
    "        \"https://www.immoweb.be/en/classified/house/for-sale/schaerbeek/1030/11150110\"\n",
    "    ]\n",
    "\n",
    "    # Define the text file name\n",
    "    txt_file = \"immoweb_data.txt\"\n",
    "\n",
    "    # Create a lock for file writing\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create threads for scraping data from each URL\n",
    "    threads = []\n",
    "    for url in urls:\n",
    "        thread = threading.Thread(target=scrape_immoweb_data, args=(url, txt_file, lock))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    # Wait for all threads to finish\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate and print the total execution time\n",
    "    print(f\"Total execution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
