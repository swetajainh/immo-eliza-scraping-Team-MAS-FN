{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/44j74rnn4cn95_4v5x1zgpgr0000gn/T/ipykernel_15083/3991096577.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates found!\n",
      "Scraping completed!\n",
      "Total URLs scraped: 12000\n",
      "Total time: 43.00734281539917 seconds\n",
      "\n",
      "Scraping individual pages...\n",
      "Scraping completed!raped: 12001\n",
      "Total time spent scraping: 2538.2375497817993 seconds\n",
      "Original DataFrame:\n",
      "                                                     url          id  \\\n",
      "0      https://www.immoweb.be/en/classified/apartment...  11153088.0   \n",
      "1      https://www.immoweb.be/en/classified/apartment...  11155018.0   \n",
      "2      https://www.immoweb.be/en/classified/house/for...  11144455.0   \n",
      "3      https://www.immoweb.be/en/classified/flat-stud...  11144586.0   \n",
      "4      https://www.immoweb.be/en/classified/mixed-use...  11147395.0   \n",
      "...                                                  ...         ...   \n",
      "11995  https://www.immoweb.be/en/classified/apartment...  11148831.0   \n",
      "11996  https://www.immoweb.be/en/classified/duplex/fo...  11148830.0   \n",
      "11997  https://www.immoweb.be/en/classified/duplex/fo...  11148829.0   \n",
      "11998  https://www.immoweb.be/en/classified/apartment...  11148828.0   \n",
      "11999  https://www.immoweb.be/en/classified/house/for...  11148827.0   \n",
      "\n",
      "         region  province            locality zip_code property_type  \\\n",
      "0      Brussels  Brussels            Brussels     1000     APARTMENT   \n",
      "1      Brussels  Brussels             Ixelles     1050     APARTMENT   \n",
      "2      Wallonie     Liège             Angleur     4031         HOUSE   \n",
      "3      Brussels  Brussels          Schaerbeek     1030     APARTMENT   \n",
      "4      Flanders   Antwerp           ANTWERPEN     2000         HOUSE   \n",
      "...         ...       ...                 ...      ...           ...   \n",
      "11995  Flanders   Antwerp             Antwerp     2050     APARTMENT   \n",
      "11996  Flanders   Antwerp  Zwijndrecht Burcht     2070     APARTMENT   \n",
      "11997  Flanders   Antwerp  Zwijndrecht Burcht     2070     APARTMENT   \n",
      "11998  Flanders   Antwerp    Antwerpen Deurne     2100     APARTMENT   \n",
      "11999  Wallonie   Hainaut            Péruwelz     7600         HOUSE   \n",
      "\n",
      "         property_subtype     price  number_rooms  ...  furnished fireplace  \\\n",
      "0               APARTMENT  795000.0           3.0  ...      False       NaN   \n",
      "1               APARTMENT  795000.0           3.0  ...      False       NaN   \n",
      "2                   HOUSE  139000.0           3.0  ...       None      -1.0   \n",
      "3             FLAT_STUDIO  165000.0           0.0  ...       True      -1.0   \n",
      "4      MIXED_USE_BUILDING  167000.0           1.0  ...       None       NaN   \n",
      "...                   ...       ...           ...  ...        ...       ...   \n",
      "11995           APARTMENT  595000.0           2.0  ...      False       NaN   \n",
      "11996              DUPLEX  575000.0           2.0  ...      False       NaN   \n",
      "11997              DUPLEX  575000.0           2.0  ...      False       NaN   \n",
      "11998           APARTMENT  185000.0           2.0  ...      False       NaN   \n",
      "11999               HOUSE   85000.0           2.0  ...       None       NaN   \n",
      "\n",
      "      terrace  terrace_area garden  garden_area surface_land  number_facades  \\\n",
      "0        True          15.0   None          NaN      UNKNOWN               2   \n",
      "1        None           NaN   None          NaN      UNKNOWN               2   \n",
      "2        True          11.0   None          NaN           63               2   \n",
      "3        True           1.0   None          NaN      UNKNOWN               2   \n",
      "4        True           3.0   None          NaN          100               2   \n",
      "...       ...           ...    ...          ...          ...             ...   \n",
      "11995    True          53.0   None          NaN      UNKNOWN               2   \n",
      "11996    True          15.0   None          NaN      UNKNOWN               2   \n",
      "11997    True          44.0   None          NaN      UNKNOWN               2   \n",
      "11998    None           NaN   None          NaN      UNKNOWN               2   \n",
      "11999    None           NaN   None          NaN          140               2   \n",
      "\n",
      "      swimming_pool  building_state  \n",
      "0             False            GOOD  \n",
      "1             False   TO_BE_DONE_UP  \n",
      "2             False            GOOD  \n",
      "3              None            GOOD  \n",
      "4              None  JUST_RENOVATED  \n",
      "...             ...             ...  \n",
      "11995         False          AS_NEW  \n",
      "11996         False          AS_NEW  \n",
      "11997         False          AS_NEW  \n",
      "11998          None          AS_NEW  \n",
      "11999          None   TO_BE_DONE_UP  \n",
      "\n",
      "[12000 rows x 22 columns]\n",
      "Unique values in 'region' column before recoding:\n",
      "['Brussels' 'Wallonie' 'Flanders' None nan]\n",
      "\n",
      "DataFrame with 'furnished' column recoded:\n",
      "                                                 url          id  region  \\\n",
      "0  https://www.immoweb.be/en/classified/apartment...  11153088.0     1.0   \n",
      "1  https://www.immoweb.be/en/classified/apartment...  11155018.0     1.0   \n",
      "2  https://www.immoweb.be/en/classified/house/for...  11144455.0     2.0   \n",
      "3  https://www.immoweb.be/en/classified/flat-stud...  11144586.0     1.0   \n",
      "4  https://www.immoweb.be/en/classified/mixed-use...  11147395.0     3.0   \n",
      "\n",
      "   province    locality zip_code property_type    property_subtype     price  \\\n",
      "0  Brussels    Brussels     1000     APARTMENT           APARTMENT  795000.0   \n",
      "1  Brussels     Ixelles     1050     APARTMENT           APARTMENT  795000.0   \n",
      "2     Liège     Angleur     4031         HOUSE               HOUSE  139000.0   \n",
      "3  Brussels  Schaerbeek     1030     APARTMENT         FLAT_STUDIO  165000.0   \n",
      "4   Antwerp   ANTWERPEN     2000         HOUSE  MIXED_USE_BUILDING  167000.0   \n",
      "\n",
      "   number_rooms  ...  furnished fireplace  terrace  terrace_area  garden  \\\n",
      "0           3.0  ...        0.0       NaN      1.0          15.0     NaN   \n",
      "1           3.0  ...        0.0       NaN      NaN           NaN     NaN   \n",
      "2           3.0  ...        NaN      -1.0      1.0          11.0     NaN   \n",
      "3           0.0  ...        1.0      -1.0      1.0           1.0     NaN   \n",
      "4           1.0  ...        NaN       NaN      1.0           3.0     NaN   \n",
      "\n",
      "   garden_area  surface_land  number_facades swimming_pool  building_state  \n",
      "0          NaN       UNKNOWN               2           0.0            GOOD  \n",
      "1          NaN       UNKNOWN               2           0.0   TO_BE_DONE_UP  \n",
      "2          NaN            63               2           0.0            GOOD  \n",
      "3          NaN       UNKNOWN               2           NaN            GOOD  \n",
      "4          NaN           100               2           NaN  JUST_RENOVATED  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "##Immo Final Code  \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "# Function to scrape URLs\n",
    "def scrape_urls(page_num):\n",
    "    base_url = f\"https://www.immoweb.be/en/search/house-and-apartment/for-sale?countries=BE&page={page_num}&orderBy=relevance\"\n",
    "    r = requests.get(base_url)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "    urls = []\n",
    "    for elem in soup.find_all(\"a\", attrs={\"class\": \"card__title-link\"}):\n",
    "        urls.append(elem.get('href'))\n",
    "\n",
    "    # Save URLs to file - full_list.txt (local storage)\n",
    "    with open(\"full_list.txt\", \"a\") as f:\n",
    "        for url in urls:\n",
    "            f.write(url + '\\n')\n",
    "    return urls\n",
    "\n",
    "\n",
    "def thread_scraping():\n",
    "    full_list_url = []\n",
    "    num_pages = 200\n",
    "\n",
    "    # Create a list to store threads\n",
    "    threads = []\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    # Create and start threads\n",
    "    for i in range(1, num_pages + 1):\n",
    "        #This line creates a new thread (t) with a target function.\n",
    "        #The target function is a lambda function that calls scrape_urls(i) for the current value of i.\n",
    "        t = threading.Thread(target=lambda: full_list_url.extend(scrape_urls(i)))\n",
    "        #The newly created thread t is appended to the list threads,\n",
    "        # which keeps track of all the threads created.\n",
    "        threads.append(t)\n",
    "        #This starts the thread t, which executes the target function asynchronously.\n",
    "        t.start()\n",
    "\n",
    "    # Wait for all threads to complete and then join\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    end_time = time.time()  # Stop timer\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(\"Scraping completed!\")\n",
    "    print(\"Total URLs scraped:\", len(full_list_url))\n",
    "    print(\"Total time:\", execution_time, \"seconds\")\n",
    "    return full_list_url\n",
    "\n",
    "#thread_scraping()\n",
    "\n",
    "\n",
    "# Function to report the progress of the scrapping process\n",
    "def reporting(str, i):\n",
    "    \"\"\"Reports on scraping progress\"\"\"\n",
    "    sys.stdout.write(str + ' %d\\r' %i)\n",
    "    sys.stdout.flush()\n",
    "    return\n",
    "\n",
    "# Reading URLs from the file\n",
    "with open(\"./full_list.txt\", \"r\") as file:\n",
    "    original_urls = file.readlines()\n",
    "\n",
    "# Removing duplicates\n",
    "unique_urls = list(set(original_urls))\n",
    "\n",
    "# Check if duplicates exist\n",
    "if len(original_urls) != len(unique_urls):\n",
    "    print(\"Duplicates found!\")\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n",
    "\n",
    "\n",
    "def counter():\n",
    "    \"\"\"Creates a global counter for use in list comprehension\"\"\"\n",
    "    global counters\n",
    "    if counters < 1:\n",
    "        counters = 1\n",
    "    else:\n",
    "        counters +=1\n",
    "    return\n",
    "\n",
    "def scrape_house(url):\n",
    "    \"\"\"Scrapes all the info from a house listing\"\"\"\n",
    "\n",
    "    # Get the house listing and make a soup\n",
    "    try:\n",
    "        house_page = requests.get(url)\n",
    "        house_page = BeautifulSoup(house_page.text, 'html.parser')\n",
    "    # Return an empty dictionary if we can't parse the URL\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    # Get the hidden info from the java script\n",
    "    try:\n",
    "        #To extract the JSON-like data, the function uses a regular expression\n",
    "        # (regex = r\"window.classified = (\\{.*\\})\") to capture the JSON-like data enclosed within curly braces {}.\n",
    "        regex = r\"window.classified = (\\{.*\\})\" # Only captures what's between brackets\n",
    "        script = house_page.find('div',attrs={\"id\":\"main-container\"}).script.text\n",
    "        script = re.findall(regex, script)\n",
    "        script = json.loads(script[0])\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    final_dictionary = {}\n",
    "\n",
    "\n",
    "    # URL\n",
    "    try:\n",
    "        final_dictionary['url'] = url\n",
    "    except:\n",
    "        final_dictionary['url'] = 'UNKNOWN'\n",
    "    #id\n",
    "    try:\n",
    "        final_dictionary['id'] = script['id']\n",
    "    except:\n",
    "        final_dictionary['id'] = 'UNKNOWN'\n",
    "    # Region\n",
    "    try:\n",
    "        final_dictionary['region'] = script['property']['location']['region']\n",
    "    except:\n",
    "        final_dictionary['region'] = 'UNKNOWN'\n",
    "    # Province\n",
    "    try:\n",
    "        final_dictionary['province'] = script['property']['location']['province']\n",
    "    except:\n",
    "        final_dictionary['province'] = 'UNKNOWN'\n",
    "    # Locality\n",
    "    try:\n",
    "        final_dictionary['locality'] = script['property']['location']['locality']\n",
    "    except:\n",
    "        final_dictionary['locality'] = 'UNKNOWN'\n",
    "    # ZIP Code\n",
    "    try:\n",
    "        final_dictionary['zip_code'] = script['property']['location']['postalCode']\n",
    "    except:\n",
    "        final_dictionary['zip_code'] = 'UNKNOWN'\n",
    "    # Type of property\n",
    "    try:\n",
    "        final_dictionary['property_type'] = script['property']['type']\n",
    "    except:\n",
    "        final_dictionary['property_type'] = 'UNKNOWN'\n",
    "    # Subtype of property\n",
    "    try:\n",
    "        final_dictionary['property_subtype'] = script['property']['subtype']\n",
    "    except:\n",
    "        final_dictionary['property_subtype'] = 'UNKNOWN'\n",
    "    # Price\n",
    "    try:\n",
    "        final_dictionary['price'] = script['price']['mainValue']\n",
    "    except:\n",
    "        final_dictionary['price'] = 'UNKNOWN'\n",
    "    # Number of rooms\n",
    "    try:\n",
    "        final_dictionary['number_rooms'] = script['property']['bedroomCount']\n",
    "    except:\n",
    "        final_dictionary['number_rooms'] = 'UNKNOWN'\n",
    "    # Living area\n",
    "    try:\n",
    "        final_dictionary['living_area'] = script['property']['netHabitableSurface']\n",
    "    except:\n",
    "        final_dictionary['living_area'] = 'UNKNOWN'\n",
    "    # Fully equipped kitchen (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['kitchen'] = script['property']['kitchen']['type']\n",
    "    except:\n",
    "        final_dictionary['kitchen'] = 0\n",
    "    # Furnished (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['furnished'] = script['transaction']['sale']['isFurnished']\n",
    "    except:\n",
    "        final_dictionary['furnished'] = 'UNKNOWN'\n",
    "    # Open fire (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['fireplace'] = script['property']['fireplaceCount']\n",
    "    except:\n",
    "        final_dictionary['fireplace'] = 0\n",
    "    # Terrace (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['terrace'] = script['property']['hasTerrace']\n",
    "    except:\n",
    "        final_dictionary['terrace'] = 0\n",
    "    # If yes: Area\n",
    "    try:\n",
    "        final_dictionary['terrace_area'] = script['property']['terraceSurface']\n",
    "    except:\n",
    "        final_dictionary['terrace_area'] = 0\n",
    "    # Garden\n",
    "    try:\n",
    "        final_dictionary['garden'] = script['property']['hasGarden']\n",
    "    except:\n",
    "        final_dictionary['garden'] = 0\n",
    "    # If yes: Area\n",
    "    try:\n",
    "        final_dictionary['garden_area'] = script['property']['gardenSurface']\n",
    "    except:\n",
    "        final_dictionary['garden_area'] = 0\n",
    "    # Surface of the land\n",
    "    try:\n",
    "        final_dictionary['surface_land'] = script['property']['land']['surface']\n",
    "    except:\n",
    "        final_dictionary['surface_land'] = \"UNKNOWN\"\n",
    "    # Number of facades\n",
    "    try:\n",
    "        final_dictionary['number_facades'] = script['property']['building']['facadeCount']\n",
    "    except:\n",
    "        final_dictionary['number_facades'] = \"UNKNOWN\"\n",
    "    # Swimming pool (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['swimming_pool'] =  script['property']['hasSwimmingPool']\n",
    "    except:\n",
    "        final_dictionary['swimming_pool'] = 0\n",
    "    # State of the building (New, to be renovated, ...)\n",
    "    try:\n",
    "        final_dictionary['building_state'] = script['property']['building']['condition']\n",
    "    except:\n",
    "        final_dictionary['building_state'] = 'UNKNOWN'\n",
    "\n",
    "\n",
    "    return final_dictionary\n",
    "\n",
    "def create_dataframe():\n",
    "    \"\"\"Will scrape info from house pages and create a pandas DataFrame from the info we scrape\"\"\"\n",
    "    # Initialize list and fetch all URLs\n",
    "    houses_links = []\n",
    "    houses_links = thread_scraping()\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Scraping individual pages...\")\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    # Scrape info from house pages concurrently\n",
    "    with ThreadPoolExecutor(max_workers=30) as executor:\n",
    "        futures = [(executor.submit(scrape_house, url), counter(), reporting(\"Individual pages scraped:\", counters),\n",
    "                    time.sleep(.2)) for url in houses_links]\n",
    "        results =  [item[0].result() for item in futures]\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "    # Export our dataset to a csv\"\n",
    "    df.to_csv(csv_path, index = True)\n",
    "\n",
    "    end_time = time.time()  # Stop timer\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(\"Scraping completed!\")\n",
    "    print(\"Total time spent scraping:\", execution_time, \"seconds\")\n",
    "    return df\n",
    "\n",
    "# Initialize counter for the counter function\n",
    "counters = 1\n",
    "\n",
    "# Build path to file\n",
    "# Selects current working directory\n",
    "cwd = Path.cwd()\n",
    "output_folder = (cwd / 'data_output').resolve() # Adjusted CSV file path and name\n",
    "csv_filename = \"house_apart_sale.csv\"\n",
    "csv_path = (output_folder / csv_filename).resolve()\n",
    "url_path = './full_list.txt'\n",
    "csv_path = (cwd / csv_path).resolve()\n",
    "url_path = (cwd / url_path).resolve()\n",
    "\n",
    "# Ensure the \"output\" folder exists\n",
    "output_folder = (cwd / 'data_output').resolve()\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset = create_dataframe()\n",
    "print(\"Original DataFrame:\")\n",
    "print(dataset)\n",
    "\n",
    "# Print unique values in the 'furnished' column before recoding\n",
    "print(\"Unique values in 'region' column before recoding:\")\n",
    "print(dataset['region'].unique())\n",
    "\n",
    "# Print 'furnished' column before recoding\n",
    "# print(\"\\n'furnished' column before recoding:\")\n",
    "# print(dataset['furnished'].head())\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "binary_columns = ['furnished', 'terrace', 'garden', 'swimming_pool']\n",
    "\n",
    "# Convert 'TRUE'/'FALSE' strings to 1/0 integers and handle empty values\n",
    "for column in binary_columns:\n",
    "    dataset[column] = dataset[column].apply(lambda x: 1 if str(x).upper() == 'TRUE' else (0 if str(x).upper() == 'FALSE' else None) if x != '' else None)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "tria_columns = ['region']\n",
    "\n",
    "# Define the mapping for 'region'\n",
    "region_mapping = {'Brussels': 1, 'Wallonie': 2, 'Flanders': 3, '': None}\n",
    "\n",
    "# Convert strings to integers and handle empty cells\n",
    "for column in tria_columns:\n",
    "    dataset[column] = dataset[column].map(region_mapping)\n",
    "\n",
    "# Save the entire DataFrame to a CSV file\n",
    "csv_output_path = output_folder / 'house_apart_sale.csv'\n",
    "dataset.to_csv(csv_output_path, index=False)\n",
    "\n",
    "print(\"\\nDataFrame with 'furnished' column recoded:\")\n",
    "print(dataset.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
