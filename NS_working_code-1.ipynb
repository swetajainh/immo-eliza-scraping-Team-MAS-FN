{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completed!\n",
      "Total URLs scraped: 120\n",
      "Total time: 1.8549697399139404 seconds\n",
      "Scraping completed!\n",
      "Total URLs scraped: 120\n",
      "Total time: 1.329416036605835 seconds\n",
      "\n",
      "Scraping individual pages...\n",
      "Scraping completed!                        \n",
      "Total time spent scraping: 28.6515212059021 seconds\n",
      "Original DataFrame:\n",
      "                                                   url        id    region  \\\n",
      "0    https://www.immoweb.be/en/classified/new-real-...   9466117  Flanders   \n",
      "1    https://www.immoweb.be/en/classified/new-real-...  11155862  Flanders   \n",
      "2    https://www.immoweb.be/en/classified/new-real-...  11155383  Flanders   \n",
      "3    https://www.immoweb.be/en/classified/apartment...  11157252  Flanders   \n",
      "4    https://www.immoweb.be/en/classified/new-real-...  11156389  Flanders   \n",
      "..                                                 ...       ...       ...   \n",
      "115  https://www.immoweb.be/en/classified/house/for...  11159289  Wallonie   \n",
      "116  https://www.immoweb.be/en/classified/villa/for...  11159288  Wallonie   \n",
      "117  https://www.immoweb.be/en/classified/house/for...  11118544  Wallonie   \n",
      "118  https://www.immoweb.be/en/classified/country-c...  10848918  Wallonie   \n",
      "119  https://www.immoweb.be/en/classified/new-real-...  10900680  Flanders   \n",
      "\n",
      "            province             locality zip_code  Longitude   Latitude  \\\n",
      "0      West Flanders         Beveren-Leie     8791   3.335321  50.870701   \n",
      "1      East Flanders                 Gent     9000   3.707025  50.996953   \n",
      "2      East Flanders           Zwijnaarde     9052   3.707025  50.996953   \n",
      "3            Antwerp            BONHEIDEN     2820   4.553796  51.036616   \n",
      "4    Flemish Brabant              Dilbeek     1700   4.256911  50.871359   \n",
      "..               ...                  ...      ...        ...        ...   \n",
      "115            Li√®ge  Verviers Lambermont     4800   5.831110  50.590627   \n",
      "116          Hainaut           Estaimpuis     7730        NaN        NaN   \n",
      "117          Hainaut             Herseaux     7712        NaN        NaN   \n",
      "118          Hainaut             Mouscron     7700        NaN        NaN   \n",
      "119    East Flanders          Nieuwenhove     9506   3.979988  50.786549   \n",
      "\n",
      "       property_type property_subtype  ...  furnished  fireplace  terrace  \\\n",
      "0        HOUSE_GROUP      HOUSE_GROUP  ...       None        NaN     None   \n",
      "1    APARTMENT_GROUP  APARTMENT_GROUP  ...       None        NaN     None   \n",
      "2    APARTMENT_GROUP  APARTMENT_GROUP  ...       None        NaN     None   \n",
      "3          APARTMENT        APARTMENT  ...       None        NaN     True   \n",
      "4    APARTMENT_GROUP  APARTMENT_GROUP  ...       None        NaN     None   \n",
      "..               ...              ...  ...        ...        ...      ...   \n",
      "115            HOUSE            HOUSE  ...      False        NaN     True   \n",
      "116            HOUSE            VILLA  ...      False        NaN     True   \n",
      "117            HOUSE            HOUSE  ...      False        NaN     True   \n",
      "118            HOUSE  COUNTRY_COTTAGE  ...      False        NaN     True   \n",
      "119      HOUSE_GROUP      HOUSE_GROUP  ...       None        NaN     None   \n",
      "\n",
      "    terrace_area garden  garden_area surface_land  number_facades  \\\n",
      "0            NaN   None          NaN      UNKNOWN         UNKNOWN   \n",
      "1            NaN   None          NaN      UNKNOWN         UNKNOWN   \n",
      "2            NaN   None          NaN      UNKNOWN         UNKNOWN   \n",
      "3            NaN   None          NaN      UNKNOWN               3   \n",
      "4            NaN   None          NaN      UNKNOWN         UNKNOWN   \n",
      "..           ...    ...          ...          ...             ...   \n",
      "115          4.0   True         25.0          110               2   \n",
      "116          NaN   None          NaN         2990               4   \n",
      "117        180.0   True       1350.0         1800               2   \n",
      "118          NaN   True        900.0         1272               4   \n",
      "119          NaN   None          NaN      UNKNOWN         UNKNOWN   \n",
      "\n",
      "    swimming_pool  building_state  \n",
      "0            None         UNKNOWN  \n",
      "1            None         UNKNOWN  \n",
      "2            None         UNKNOWN  \n",
      "3            None            GOOD  \n",
      "4            None         UNKNOWN  \n",
      "..            ...             ...  \n",
      "115         False            GOOD  \n",
      "116          True  JUST_RENOVATED  \n",
      "117         False          AS_NEW  \n",
      "118         False            GOOD  \n",
      "119          None         UNKNOWN  \n",
      "\n",
      "[120 rows x 24 columns]\n",
      "Unique values in 'region' column before recoding:\n",
      "['Flanders' 'Brussels' 'Wallonie']\n",
      "\n",
      "DataFrame with 'furnished' column recoded:\n",
      "                                                 url        id  region  \\\n",
      "0  https://www.immoweb.be/en/classified/new-real-...   9466117     3.0   \n",
      "1  https://www.immoweb.be/en/classified/new-real-...  11155862     3.0   \n",
      "2  https://www.immoweb.be/en/classified/new-real-...  11155383     3.0   \n",
      "3  https://www.immoweb.be/en/classified/apartment...  11157252     3.0   \n",
      "4  https://www.immoweb.be/en/classified/new-real-...  11156389     3.0   \n",
      "\n",
      "          province      locality zip_code  Longitude   Latitude  \\\n",
      "0    West Flanders  Beveren-Leie     8791   3.335321  50.870701   \n",
      "1    East Flanders          Gent     9000   3.707025  50.996953   \n",
      "2    East Flanders    Zwijnaarde     9052   3.707025  50.996953   \n",
      "3          Antwerp     BONHEIDEN     2820   4.553796  51.036616   \n",
      "4  Flemish Brabant       Dilbeek     1700   4.256911  50.871359   \n",
      "\n",
      "     property_type property_subtype  ...  furnished  fireplace  terrace  \\\n",
      "0      HOUSE_GROUP      HOUSE_GROUP  ...        NaN        NaN      NaN   \n",
      "1  APARTMENT_GROUP  APARTMENT_GROUP  ...        NaN        NaN      NaN   \n",
      "2  APARTMENT_GROUP  APARTMENT_GROUP  ...        NaN        NaN      NaN   \n",
      "3        APARTMENT        APARTMENT  ...        NaN        NaN      1.0   \n",
      "4  APARTMENT_GROUP  APARTMENT_GROUP  ...        NaN        NaN      NaN   \n",
      "\n",
      "  terrace_area  garden  garden_area  surface_land  number_facades  \\\n",
      "0          NaN     NaN          NaN       UNKNOWN         UNKNOWN   \n",
      "1          NaN     NaN          NaN       UNKNOWN         UNKNOWN   \n",
      "2          NaN     NaN          NaN       UNKNOWN         UNKNOWN   \n",
      "3          NaN     NaN          NaN       UNKNOWN               3   \n",
      "4          NaN     NaN          NaN       UNKNOWN         UNKNOWN   \n",
      "\n",
      "   swimming_pool  building_state  \n",
      "0            NaN         UNKNOWN  \n",
      "1            NaN         UNKNOWN  \n",
      "2            NaN         UNKNOWN  \n",
      "3            NaN            GOOD  \n",
      "4            NaN         UNKNOWN  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "## FOR CODE TRIAL \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Function to scrape URLs\n",
    "def scrape_urls(page_num):\n",
    "    base_url = f\"https://www.immoweb.be/en/search/house-and-apartment/for-sale?countries=BE&page={page_num}&orderBy=relevance\"\n",
    "    r = requests.get(base_url)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "    urls = []\n",
    "    for elem in soup.find_all(\"a\", attrs={\"class\": \"card__title-link\"}):\n",
    "        urls.append(elem.get('href'))\n",
    "\n",
    "    # Save URLs to file - full_list.txt (local storage)\n",
    "    with open(\"full_list.txt\", \"a\") as f:\n",
    "        for url in urls:\n",
    "            f.write(url + '\\n')\n",
    "    return urls\n",
    "\n",
    "def thread_scraping():\n",
    "    full_list_url = []\n",
    "    num_pages = 2\n",
    "\n",
    "    # Create a list to store threads\n",
    "    threads = []\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    # Create and start threads\n",
    "    for i in range(1, num_pages + 1):\n",
    "        t = threading.Thread(target=lambda: full_list_url.extend(scrape_urls(i)))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "\n",
    "    # Wait for all threads to complete and then join\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    end_time = time.time()  # Stop timer\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(\"Scraping completed!\")\n",
    "    print(\"Total URLs scraped:\", len(full_list_url))\n",
    "    print(\"Total time:\", execution_time, \"seconds\")\n",
    "    return full_list_url\n",
    "\n",
    "thread_scraping()\n",
    "\n",
    "\n",
    "def reporting(str, i):\n",
    "    \"\"\"Reports on scraping progress\"\"\"\n",
    "    sys.stdout.write(str + ' %d\\r' %i)\n",
    "    sys.stdout.flush()\n",
    "    return\n",
    "\n",
    "# Initialize counter for the counter function\n",
    "counters = 1\n",
    "def counter():\n",
    "    \"\"\"Creates a global counter for use in list comprehension\"\"\"\n",
    "    global counters\n",
    "    if counters < 1:\n",
    "        counters = 1\n",
    "    else:\n",
    "        counters += 1\n",
    "    return\n",
    "\n",
    "def scrape_house(url):\n",
    "    \"\"\"Scrapes all the info from a house listing\"\"\"\n",
    "\n",
    "    # Get the house listing and make a soup\n",
    "    try:\n",
    "        house_page = requests.get(url)\n",
    "        house_page = BeautifulSoup(house_page.text, 'html.parser')\n",
    "    # Return an empty dictionary if we can't parse the URL\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    # Get the hidden info from the java script\n",
    "    try:\n",
    "        regex = r\"window.classified = (\\{.*\\})\" # Only captures what's between brackets\n",
    "        script = house_page.find('div',attrs={\"id\":\"main-container\"}).script.text\n",
    "        script = re.findall(regex, script)\n",
    "        script = json.loads(script[0])\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    final_dictionary = {}\n",
    "    # URL\n",
    "    try:\n",
    "        final_dictionary['url'] = url\n",
    "    except:\n",
    "        final_dictionary['url'] = 'UNKNOWN'\n",
    "    # URL adding IMMO ID\n",
    "    try:\n",
    "        final_dictionary['id'] = script['id']\n",
    "    except:\n",
    "        final_dictionary['id'] = 'UNKNOWN'\n",
    "    # Region\n",
    "    try:\n",
    "        final_dictionary['region'] = script['property']['location']['region']\n",
    "    except:\n",
    "        final_dictionary['region'] = 'UNKNOWN'\n",
    "    #  # Region\n",
    "    try:\n",
    "        final_dictionary['region'] = script['property']['location']['region']\n",
    "    except:\n",
    "        final_dictionary['region'] = 'UNKNOWN'\n",
    "    # Province\n",
    "    try:\n",
    "        final_dictionary['province'] = script['property']['location']['province']\n",
    "    except:\n",
    "        final_dictionary['province'] = 'UNKNOWN'\n",
    "    # Locality\n",
    "    try:\n",
    "        final_dictionary['locality'] = script['property']['location']['locality']\n",
    "    except:\n",
    "        final_dictionary['locality'] = 'UNKNOWN'\n",
    "    # ZIP Code\n",
    "    try:\n",
    "        final_dictionary['zip_code'] = script['property']['location']['postalCode']\n",
    "    except:\n",
    "        final_dictionary['zip_code'] = 'UNKNOWN'\n",
    "    # Longitude\n",
    "    try:\n",
    "        final_dictionary['Longitude'] = script['property']['location']['longitude']\n",
    "    except:\n",
    "        final_dictionary['Longitude'] = 'UNKNOWN'\n",
    "    # Latitude\n",
    "    try:\n",
    "        final_dictionary['Latitude'] = script['property']['location']['latitude']\n",
    "    except:\n",
    "        final_dictionary['Latitude'] = 'UNKNOWN'\n",
    "    # Type of property\n",
    "    try:\n",
    "        final_dictionary['property_type'] = script['property']['type']\n",
    "    except:\n",
    "        final_dictionary['property_type'] = 'UNKNOWN'\n",
    "    # Subtype of property\n",
    "    try:\n",
    "        final_dictionary['property_subtype'] = script['property']['subtype']\n",
    "    except:\n",
    "        final_dictionary['property_subtype'] = 'UNKNOWN'\n",
    "    # Price\n",
    "    try:\n",
    "        final_dictionary['price'] = script['price']['mainValue']\n",
    "    except:\n",
    "        final_dictionary['price'] = 'UNKNOWN'\n",
    "    # Number of rooms\n",
    "    try:\n",
    "        final_dictionary['number_rooms'] = script['property']['bedroomCount']\n",
    "    except:\n",
    "        final_dictionary['number_rooms'] = 'UNKNOWN'\n",
    "    # Living area\n",
    "    try:\n",
    "        final_dictionary['living_area'] = script['property']['netHabitableSurface']\n",
    "    except:\n",
    "        final_dictionary['living_area'] = 'UNKNOWN'\n",
    "    # Fully equipped kitchen (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['kitchen'] = script['property']['kitchen']['type']\n",
    "    except:\n",
    "        final_dictionary['kitchen'] = 0\n",
    "    # Furnished (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['furnished'] = script['transaction']['sale']['isFurnished']\n",
    "    except:\n",
    "        final_dictionary['furnished'] = 'UNKNOWN'\n",
    "    # Open fire (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['fireplace'] = script['property']['fireplaceCount']\n",
    "    except:\n",
    "        final_dictionary['fireplace'] = 0\n",
    "    # Terrace (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['terrace'] = script['property']['hasTerrace']\n",
    "    except:\n",
    "        final_dictionary['terrace'] = 0\n",
    "    # If yes: Area\n",
    "    try:\n",
    "        final_dictionary['terrace_area'] = script['property']['terraceSurface']\n",
    "    except:\n",
    "        final_dictionary['terrace_area'] = 0\n",
    "    # Garden\n",
    "    try:\n",
    "        final_dictionary['garden'] = script['property']['hasGarden']\n",
    "    except:\n",
    "        final_dictionary['garden'] = 0\n",
    "    # If yes: Area\n",
    "    try:\n",
    "        final_dictionary['garden_area'] = script['property']['gardenSurface']\n",
    "    except:\n",
    "        final_dictionary['garden_area'] = 0\n",
    "    # Surface of the land\n",
    "    try:\n",
    "        final_dictionary['surface_land'] = script['property']['land']['surface']\n",
    "    except:\n",
    "        final_dictionary['surface_land'] = \"UNKNOWN\"\n",
    "    # Number of facades\n",
    "    try:\n",
    "        final_dictionary['number_facades'] = script['property']['building']['facadeCount']\n",
    "    except:\n",
    "        final_dictionary['number_facades'] = \"UNKNOWN\"\n",
    "    # Swimming pool (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['swimming_pool'] =  script['property']['hasSwimmingPool']\n",
    "    except:\n",
    "        final_dictionary['swimming_pool'] = 0\n",
    "    # State of the building (New, to be renovated, ...)\n",
    "    try:\n",
    "        final_dictionary['building_state'] = script['property']['building']['condition']\n",
    "    except:\n",
    "        final_dictionary['building_state'] = 'UNKNOWN'\n",
    "\n",
    "    return final_dictionary\n",
    "\n",
    "\n",
    "    return final_dictionary\n",
    "\n",
    "def create_dataframe():\n",
    "    \"\"\"Will scrape info from house pages and create a pandas DataFrame from the info we scrape\"\"\"\n",
    "    # Initialize list and fetch all URLs\n",
    "    houses_links = []\n",
    "    houses_links = thread_scraping()\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Scraping individual pages...\")\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    # Scrape info from house pages concurrently\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [(executor.submit(scrape_house, url), counter(), reporting(\"Individual pages scraped:\", counters), time.sleep(.2)) for url in houses_links]\n",
    "        results =  [item[0].result() for item in futures]\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "    # Export our dataset to a csv\"\n",
    "    # Build path to file\n",
    "    # Select current working directory \n",
    "        cwd = Path.cwd()\n",
    "    df.to_csv(csv_path, index = True)\n",
    "\n",
    "    end_time = time.time()  # Stop timer\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(\"Scraping completed!                        \")\n",
    "    print(\"Total time spent scraping:\", execution_time, \"seconds\")\n",
    "    return df\n",
    "\n",
    "# Initialize counter for the counter function\n",
    "counters = 1\n",
    "\n",
    "# Build path to file\n",
    "# Selects current working directory\n",
    "cwd = Path.cwd()\n",
    "output_folder = (cwd / 'data_output').resolve() # Adjusted CSV file path and name\n",
    "csv_filename = \"house_apart_sale.csv\"\n",
    "csv_path = (output_folder / csv_filename).resolve()\n",
    "url_path = './full_list.txt'\n",
    "csv_path = (cwd / csv_path).resolve()\n",
    "url_path = (cwd / url_path).resolve()\n",
    "\n",
    "# Ensure the \"output\" folder exists\n",
    "output_folder = (cwd / 'data_output').resolve()\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset = create_dataframe()\n",
    "print(\"Original DataFrame:\")\n",
    "print(dataset)\n",
    "\n",
    "# Print unique values in the 'furnished' column before recoding\n",
    "print(\"Unique values in 'region' column before recoding:\")\n",
    "print(dataset['region'].unique())\n",
    "\n",
    "# Print 'furnished' column before recoding\n",
    "# print(\"\\n'furnished' column before recoding:\")\n",
    "# print(dataset['furnished'].head())\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "binary_columns = ['furnished', 'terrace', 'garden', 'swimming_pool']\n",
    "\n",
    "# Convert 'TRUE'/'FALSE' strings to 1/0 integers and handle empty values\n",
    "for column in binary_columns:\n",
    "    dataset[column] = dataset[column].apply(lambda x: 1 if str(x).upper() == 'TRUE' else (0 if str(x).upper() == 'FALSE' else None) if x != '' else None)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "tria_columns = ['region']\n",
    "\n",
    "# Define the mapping for 'region'\n",
    "region_mapping = {'Brussels': 1, 'Wallonie': 2, 'Flanders': 3, '': None}\n",
    "\n",
    "# Convert strings to integers and handle empty cells\n",
    "for column in tria_columns:\n",
    "    dataset[column] = dataset[column].map(region_mapping)\n",
    "    \n",
    "# Save the entire DataFrame to a CSV file\n",
    "csv_output_path = output_folder / 'recoded_dataset.csv'\n",
    "dataset.to_csv(csv_output_path, index=False)\n",
    "\n",
    "print(\"\\nDataFrame with 'furnished' column recoded:\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "tria_columns = ['region']\n",
    "\n",
    "# Define the mapping for 'region'\n",
    "region_mapping = {'Brussels': 1, 'Wallonie': 2, 'Flanders': 3, '': None}\n",
    "\n",
    "# Convert strings to integers and handle empty cells\n",
    "for column in tria_columns:\n",
    "    dataset[column] = dataset[column].map(region_mapping)\n",
    "\n",
    "# Save the entire DataFrame to a CSV file\n",
    "csv_output_path = output_folder / 'recoded_dataset.csv'\n",
    "dataset.to_csv(csv_output_path, index=False)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"\\nDataFrame with 'region' column recoded to 1/2/3/None:\")\n",
    "print(dataset.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values in the 'furnished' column before recoding\n",
    "print(\"Unique values in 'furnished' column before recoding:\")\n",
    "print(dataset['furnished'].unique())\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "binary_columns = ['furnished']\n",
    "\n",
    "# Convert 'TRUE'/'FALSE' strings to 1/0 integers and handle empty values\n",
    "for column in binary_columns:\n",
    "    dataset[column] = dataset[column].replace({'TRUE': 1, 'FALSE': 0, '': None, ' ': None})\n",
    "\n",
    "# Save the entire DataFrame to a CSV file\n",
    "csv_output_path = output_folder / 'recoded_dataset.csv'\n",
    "dataset.to_csv(csv_output_path, index=False)\n",
    "\n",
    "# Print unique values in the 'furnished' column after recoding\n",
    "print(\"\\nDataFrame with 'furnished' column recoded:\")\n",
    "print(dataset['furnished'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the True False \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "binary_columns = ['furnished', 'terrace', 'garden', 'swimming_pool']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## working code with ID \n",
    "## FOR CODE TRIAL \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Function to scrape URLs\n",
    "def scrape_urls(page_num):\n",
    "    base_url = f\"https://www.immoweb.be/en/search/house-and-apartment/for-sale?countries=BE&page={page_num}&orderBy=relevance\"\n",
    "    r = requests.get(base_url)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "    urls = []\n",
    "    for elem in soup.find_all(\"a\", attrs={\"class\": \"card__title-link\"}):\n",
    "        urls.append(elem.get('href'))\n",
    "\n",
    "    # Save URLs to file - full_list.txt (local storage)\n",
    "    with open(\"full_list.txt\", \"a\") as f:\n",
    "        for url in urls:\n",
    "            f.write(url + '\\n')\n",
    "    return urls\n",
    "\n",
    "def thread_scraping():\n",
    "    full_list_url = []\n",
    "    num_pages = 2\n",
    "\n",
    "    # Create a list to store threads\n",
    "    threads = []\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    # Create and start threads\n",
    "    for i in range(1, num_pages + 1):\n",
    "        t = threading.Thread(target=lambda: full_list_url.extend(scrape_urls(i)))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "\n",
    "    # Wait for all threads to complete and then join\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    end_time = time.time()  # Stop timer\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(\"Scraping completed!\")\n",
    "    print(\"Total URLs scraped:\", len(full_list_url))\n",
    "    print(\"Total time:\", execution_time, \"seconds\")\n",
    "    return full_list_url\n",
    "\n",
    "thread_scraping()\n",
    "\n",
    "\n",
    "def reporting(str, i):\n",
    "    \"\"\"Reports on scraping progress\"\"\"\n",
    "    sys.stdout.write(str + ' %d\\r' %i)\n",
    "    sys.stdout.flush()\n",
    "    return\n",
    "\n",
    "# Initialize counter for the counter function\n",
    "counters = 1\n",
    "def counter():\n",
    "    \"\"\"Creates a global counter for use in list comprehension\"\"\"\n",
    "    global counters\n",
    "    if counters < 1:\n",
    "        counters = 1\n",
    "    else:\n",
    "        counters += 1\n",
    "    return\n",
    "\n",
    "def scrape_house(url):\n",
    "    \"\"\"Scrapes all the info from a house listing\"\"\"\n",
    "\n",
    "    # Get the house listing and make a soup\n",
    "    try:\n",
    "        house_page = requests.get(url)\n",
    "        house_page = BeautifulSoup(house_page.text, 'html.parser')\n",
    "    # Return an empty dictionary if we can't parse the URL\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    # Get the hidden info from the java script\n",
    "    try:\n",
    "        regex = r\"window.classified = (\\{.*\\})\" # Only captures what's between brackets\n",
    "        script = house_page.find('div',attrs={\"id\":\"main-container\"}).script.text\n",
    "        script = re.findall(regex, script)\n",
    "        script = json.loads(script[0])\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    final_dictionary = {}\n",
    "    # URL\n",
    "    try:\n",
    "        final_dictionary['url'] = url\n",
    "    except:\n",
    "        final_dictionary['url'] = 'UNKNOWN'\n",
    "    # URL adding IMMO ID\n",
    "    try:\n",
    "        final_dictionary['id'] = script['id']\n",
    "    except:\n",
    "        final_dictionary['id'] = 'UNKNOWN'\n",
    "    # Region\n",
    "    try:\n",
    "        final_dictionary['region'] = script['property']['location']['region']\n",
    "    except:\n",
    "        final_dictionary['region'] = 'UNKNOWN'\n",
    "    #  # Region\n",
    "    try:\n",
    "        final_dictionary['region'] = script['property']['location']['region']\n",
    "    except:\n",
    "        final_dictionary['region'] = 'UNKNOWN'\n",
    "    # Province\n",
    "    try:\n",
    "        final_dictionary['province'] = script['property']['location']['province']\n",
    "    except:\n",
    "        final_dictionary['province'] = 'UNKNOWN'\n",
    "    # Locality\n",
    "    try:\n",
    "        final_dictionary['locality'] = script['property']['location']['locality']\n",
    "    except:\n",
    "        final_dictionary['locality'] = 'UNKNOWN'\n",
    "    # ZIP Code\n",
    "    try:\n",
    "        final_dictionary['zip_code'] = script['property']['location']['postalCode']\n",
    "    except:\n",
    "        final_dictionary['zip_code'] = 'UNKNOWN'\n",
    "    # Longitude\n",
    "    try:\n",
    "        final_dictionary['Longitude'] = script['property']['location']['longitude']\n",
    "    except:\n",
    "        final_dictionary['Longitude'] = 'UNKNOWN'\n",
    "    # Latitude\n",
    "    try:\n",
    "        final_dictionary['Latitude'] = script['property']['location']['latitude']\n",
    "    except:\n",
    "        final_dictionary['Latitude'] = 'UNKNOWN'\n",
    "    # Type of property\n",
    "    try:\n",
    "        final_dictionary['property_type'] = script['property']['type']\n",
    "    except:\n",
    "        final_dictionary['property_type'] = 'UNKNOWN'\n",
    "    # Subtype of property\n",
    "    try:\n",
    "        final_dictionary['property_subtype'] = script['property']['subtype']\n",
    "    except:\n",
    "        final_dictionary['property_subtype'] = 'UNKNOWN'\n",
    "    # Price\n",
    "    try:\n",
    "        final_dictionary['price'] = script['price']['mainValue']\n",
    "    except:\n",
    "        final_dictionary['price'] = 'UNKNOWN'\n",
    "    # Number of rooms\n",
    "    try:\n",
    "        final_dictionary['number_rooms'] = script['property']['bedroomCount']\n",
    "    except:\n",
    "        final_dictionary['number_rooms'] = 'UNKNOWN'\n",
    "    # Living area\n",
    "    try:\n",
    "        final_dictionary['living_area'] = script['property']['netHabitableSurface']\n",
    "    except:\n",
    "        final_dictionary['living_area'] = 'UNKNOWN'\n",
    "    # Fully equipped kitchen (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['kitchen'] = script['property']['kitchen']['type']\n",
    "    except:\n",
    "        final_dictionary['kitchen'] = 0\n",
    "    # Furnished (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['furnished'] = script['transaction']['sale']['isFurnished']\n",
    "    except:\n",
    "        final_dictionary['furnished'] = 'UNKNOWN'\n",
    "    # Open fire (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['fireplace'] = script['property']['fireplaceCount']\n",
    "    except:\n",
    "        final_dictionary['fireplace'] = 0\n",
    "    # Terrace (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['terrace'] = script['property']['hasTerrace']\n",
    "    except:\n",
    "        final_dictionary['terrace'] = 0\n",
    "    # If yes: Area\n",
    "    try:\n",
    "        final_dictionary['terrace_area'] = script['property']['terraceSurface']\n",
    "    except:\n",
    "        final_dictionary['terrace_area'] = 0\n",
    "    # Garden\n",
    "    try:\n",
    "        final_dictionary['garden'] = script['property']['hasGarden']\n",
    "    except:\n",
    "        final_dictionary['garden'] = 0\n",
    "    # If yes: Area\n",
    "    try:\n",
    "        final_dictionary['garden_area'] = script['property']['gardenSurface']\n",
    "    except:\n",
    "        final_dictionary['garden_area'] = 0\n",
    "    # Surface of the land\n",
    "    try:\n",
    "        final_dictionary['surface_land'] = script['property']['land']['surface']\n",
    "    except:\n",
    "        final_dictionary['surface_land'] = \"UNKNOWN\"\n",
    "    # Number of facades\n",
    "    try:\n",
    "        final_dictionary['number_facades'] = script['property']['building']['facadeCount']\n",
    "    except:\n",
    "        final_dictionary['number_facades'] = \"UNKNOWN\"\n",
    "    # Swimming pool (Yes/No)\n",
    "    try:\n",
    "        final_dictionary['swimming_pool'] =  script['property']['hasSwimmingPool']\n",
    "    except:\n",
    "        final_dictionary['swimming_pool'] = 0\n",
    "    # State of the building (New, to be renovated, ...)\n",
    "    try:\n",
    "        final_dictionary['building_state'] = script['property']['building']['condition']\n",
    "    except:\n",
    "        final_dictionary['building_state'] = 'UNKNOWN'\n",
    "\n",
    "    return final_dictionary\n",
    "\n",
    "\n",
    "    return final_dictionary\n",
    "\n",
    "def create_dataframe():\n",
    "    \"\"\"Will scrape info from house pages and create a pandas DataFrame from the info we scrape\"\"\"\n",
    "    # Initialize list and fetch all URLs\n",
    "    houses_links = []\n",
    "    houses_links = thread_scraping()\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Scraping individual pages...\")\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    # Scrape info from house pages concurrently\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [(executor.submit(scrape_house, url), counter(), reporting(\"Individual pages scraped:\", counters), time.sleep(.2)) for url in houses_links]\n",
    "        results =  [item[0].result() for item in futures]\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "    # Export our dataset to a csv\"\n",
    "    # Build path to file\n",
    "    # Select current working directory \n",
    "        cwd = Path.cwd()\n",
    "    df.to_csv(csv_path, index = True)\n",
    "\n",
    "    end_time = time.time()  # Stop timer\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(\"Scraping completed!                        \")\n",
    "    print(\"Total time spent scraping:\", execution_time, \"seconds\")\n",
    "    return df\n",
    "\n",
    "# Initialize counter for the counter function\n",
    "counters = 1\n",
    "\n",
    "# Build path to file\n",
    "# Selects current working directory\n",
    "cwd = Path.cwd()\n",
    "output_folder = (cwd / 'data_output').resolve() # Adjusted CSV file path and name\n",
    "csv_filename = \"house_apart_sale.csv\"\n",
    "csv_path = (output_folder / csv_filename).resolve()\n",
    "url_path = './full_list.txt'\n",
    "csv_path = (cwd / csv_path).resolve()\n",
    "url_path = (cwd / url_path).resolve()\n",
    "\n",
    "\n",
    "# Ensure the \"output\" folder exists\n",
    "output_folder = (cwd / 'data_output').resolve()\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset = create_dataframe()\n",
    "print(dataset)\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "column_names = dataset.columns\n",
    "print(column_names)\n",
    "\n",
    "# Replace 'your_file.csv' with the actual path to your CSV file\n",
    "csv_file_path = './data_output/house_apart_sale.csv'\n",
    "\n",
    "# Read CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# List of columns to convert from yes/no strings to 1/0 integers\n",
    "binary_columns = ['furnished']\n",
    "\n",
    "# Convert yes/no strings to 1/0 integers and handle empty values\n",
    "for column in binary_columns:\n",
    "    df[column] = df[column].astype(str).str.upper().str.strip().map({'TRUE': 1, 'FALSE': 0, '': None})\n",
    "     \n",
    "# Display the updated DataFrame\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
